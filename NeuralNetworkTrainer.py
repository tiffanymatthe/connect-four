#!/usr/bin/env python
from MCTS import MCTS
from Node import Node

from keras.models import Model
from keras.layers.normalization import BatchNormalization
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Dropout
from keras.layers.core import Lambda
from keras.layers.core import Dense
from keras.layers import Flatten
from keras.layers import Input
import tensorflow as tf

class NeuralNetworkTrainer():
    def __init__(self) -> None:
        # should store data from self-play games as training data
        # probably only keep those from last iteration
        # could also store it in files too avoid losing too much data
        pass

    @staticmethod
    def get_common_layers(inputs):
        # Returns a tensor representing the common layers
        # TODO: implement

        x = Conv2D(32, (3, 3), padding="same")(inputs)
        x = Activation("relu")(x)
        x = BatchNormalization(axis=-1)(x)
        x = MaxPooling2D(pool_size=(2, 2))(x)
        x = Dropout(0.25)(x)
        
        return x 

    @staticmethod
    def get_policy_branch(inputs):
        # Returns a tensor to put in the model output
        # TODO: implement
        """
        This is assuming that inputs are the image arrays with 6x7 dimension
        and 3 feature planes. We know that the size of the output should be 7
        from before hand therefore, that is our output size.
        """
        x = NeuralNetworkTrainer.get_common_layers(inputs)
        x = Flatten()(x)
        x = Dense(128)(x)
        x = Activation("relu")(x)
        x = BatchNormalization()(x)
        x = Dropout(0.5)(x)

        x = Dense(7)(x) #size of the output
        x = Activation("softmax", name="probability_output")(x)

        return x

    @staticmethod
    def get_value_branch(inputs):
        # Returns a tensor to put in the model output
        # TODO: implement
        """
        In this function we know that the result of this branch should be a 
        0 or a 1 representing whether the current player is going to win or not. 
        Hence, the size of the output is just 1. 

        Not sure about how to call the binary step function here. 
        """
        x = NeuralNetworkTrainer.get_common_layers(inputs)
        x = Flatten()(x)
        x = Dense(128)(x)
        x = Activation("relu")(x)
        x = BatchNormalization()(x)
        x = Dropout(0.5)(x)

        x = Dense(1)(x) #size of the output
        x = Activation("binary", name="value_output")(x)

        return x

    @staticmethod
    def get_model():
        # Returns TF model with two output branches. should already be compiled.
        # TODO: implement
        pass

    def __play_self_play_game(MCTS_iterations):
        # how to do self-play? two MCTS trees?
        # need to somehow save (s, pi, z) at intervals
        # how to get z from MCTS? is it just the result of the actual game? so need to populate at end?
        # TODO: implement
        tree = MCTS()
        board = Node()

        while (not board.is_terminal()):
            for _ in range(MCTS_iterations):
                tree.do_rollout(board)
            board = tree.choose(board)


    def __train_model(self, model):
        # trains model for the ith iteration
        # how to use train_labels if there are 2 of them?
        model.fit(..., ..., epochs=80, validation_data=..., callbacks=...)

    def iteratively_train_model(self, iterations: int, num_self_play_games: int, MCTS_iterations: int):
        """
        iterations: number of iterations to train model
        num_self_play_games: number of self-play games to play each iteration i
        MCTS_iterations: number of iterations in MCTS before picking a move for a self-play game

        Trains a deep convolution neural network for connect-4 iteratively using self-play games and MCTS.
        Neural net outputs move probabilities and predicted game winner from perspective of current player.
        Needs no external training data; that will be generated by self-play games.

        TODO: implement
        """
        for _ in range(iterations):
            for _ in range(num_self_play_games):
                self.__play_self_play_game(MCTS_iterations)
            model = NeuralNetworkTrainer.get_model()
            model.load_weights(...)
            self.__train_model(model)
        