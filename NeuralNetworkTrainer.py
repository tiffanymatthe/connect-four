#!/usr/bin/env python

class NeuralNetworkTrainer():
    def __init__(self) -> None:
        # should store data from self-play games as training data
        # probably only keep those from last iteration
        pass

    @staticmethod
    def get_common_layers(inputs):
        # Returns a tensor representing the common layers
        # TODO: implement
        pass

    @staticmethod
    def get_policy_branch(inputs):
        # Returns a tensor to put in the model output
        # TODO: implement
        x = NeuralNetworkTrainer.get_common_layers(inputs)

    @staticmethod
    def get_value_branch(inputs):
        # Returns a tensor to put in the model output
        # TODO: implement
        x = NeuralNetworkTrainer.get_common_layers(inputs)

    @staticmethod
    def get_model():
        # Returns TF model with two output branches.
        # TODO: implement
        pass

    def __play_self_play_game():
        pass

    def __train_model(self, model):
        # trains model for the ith iteration
        pass

    def iteratively_train_model(self, iterations: int, num_self_play_games: int, MCTS_iterations: int):
        """
        iterations: number of iterations to train model
        num_self_play_games: number of self-play games to play each iteration i
        MCTS_iterations: number of iterations in MCTS before picking a move for a self-play game

        Trains a deep convolution neural network for connect-4 iteratively using self-play games and MCTS. Neural net outputs move probabilities and predicted game winner from perspective of current player. Needs no external training data; that will be generated by self-play games.
        """
        model = NeuralNetworkTrainer.get_model()
